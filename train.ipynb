{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvisionのdatasetを使ってUFC101を読み込み，pytorchvideoのx3dモデルをスクラッチで学習してみる．\n",
    "\n",
    "UFC101はあらかじめダウンロードして展開済みであるとする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using cache found in /home/tamaki/.cache/torch/hub/facebookresearch_pytorchvideo_master\n",
      "Using cache found in /home/tamaki/.cache/torch/hub/facebookresearch_pytorchvideo_master\n",
      "Using cache found in /home/tamaki/.cache/torch/hub/facebookresearch_pytorchvideo_master\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# torchvisionをimportした後ではエラーが発生する（ImportError: cannot import name ***）\n",
    "# https://github.com/pytorch/hub/issues/46\n",
    "# 対応策：import torch直後に（import torchvisionをしない状態で）torch.hub.loadして，キャッシュに残しておく\n",
    "# こうすると，以降はキャッシュ（~/.cache/torch/hub/checkpoints/）が使われるのでエラーは発生しない\n",
    "\n",
    "\n",
    "# https://pytorch.org/hub/facebookresearch_pytorchvideo_x3d/\n",
    "import torch\n",
    "model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_xs', pretrained=True)\n",
    "model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_s', pretrained=True)\n",
    "model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_m', pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import DistributedSampler, RandomSampler\n",
    "\n",
    "from torchvision.models import resnet18\n",
    "from torchvision import transforms\n",
    "# from torchvision.datasets import UCF101\n",
    "\n",
    "from pytorchvideo.models import x3d\n",
    "from pytorchvideo.data import Ucf101, RandomClipSampler, UniformClipSampler\n",
    "\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    RemoveKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    ")\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    RandomCrop,\n",
    "    RandomHorizontalFlip,\n",
    ")\n",
    "\n",
    "\n",
    "import torchinfo\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argparseを真似たパラメータ設定．\n",
    "- rootで指定したディレクトリには，101クラスのサブディレクトリがあること\n",
    "- annotation_pathにはtrainlist0{1,2,3}.txtなどがあること"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.metadata_path = '/mnt/HDD10TB/dataset/UFC101/'\n",
    "        self.root = '/mnt/HDD10TB/dataset/UFC101/video/'\n",
    "        self.annotation_path = '/mnt/HDD10TB/dataset/UFC101/ucfTrainTestlist/'\n",
    "        self.frames_per_clip = 16\n",
    "        self.step_between_clips = 16\n",
    "        self.model = 'X3D'\n",
    "        self.batch_size = 8\n",
    "        self.num_workers = 24\n",
    "\n",
    "        self.video_num_subsampled = 16  # 16枚抜き出す\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose([\n",
    "    ApplyTransformToKey(\n",
    "        key=\"video\",\n",
    "        transform=Compose([\n",
    "                UniformTemporalSubsample(args.video_num_subsampled),\n",
    "                transforms.Lambda(lambda x: x / 255.),\n",
    "                Normalize((0.45, 0.45, 0.45), (0.225, 0.225, 0.225)),\n",
    "                # transforms.Lambda(lambda x: [\n",
    "                #     x, \n",
    "                #     print(type(x)),\n",
    "                #     print(x.dtype),\n",
    "                #     print(x.max()),\n",
    "                #     print(x.min()),\n",
    "                #     print(x.mean()),\n",
    "                #     ]),\n",
    "                # transforms.Lambda(lambda x: x[0]),\n",
    "                RandomShortSideScale(min_size=256, max_size=320,),\n",
    "                RandomCrop(224),\n",
    "                RandomHorizontalFlip(),\n",
    "        ]),\n",
    "    ),\n",
    "    ApplyTransformToKey(\n",
    "        key=\"label\",\n",
    "        transform=transforms.Lambda(lambda x: x - 1),\n",
    "    ),\n",
    "    RemoveKey(\"audio\"),\n",
    "])\n",
    "\n",
    "val_transform = Compose([\n",
    "    ApplyTransformToKey(\n",
    "        key=\"video\",\n",
    "        transform=Compose([\n",
    "                UniformTemporalSubsample(args.video_num_subsampled),\n",
    "                transforms.Lambda(lambda x: x / 255.),\n",
    "                Normalize((0.45, 0.45, 0.45), (0.225, 0.225, 0.225)),\n",
    "                # RandomShortSideScale(min_size=256, max_size=320,),\n",
    "                ShortSideScale(256),\n",
    "                # RandomCrop(224),\n",
    "                CenterCrop(224),\n",
    "                # RandomHorizontalFlip(),\n",
    "        ]),\n",
    "    ),\n",
    "    RemoveKey(\"audio\"),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Ucf101(\n",
    "    data_path='/mnt/HDD10TB/dataset/UFC101/ucfTrainTestlist/trainlist01.txt',  # ラベルが1から101になっているので，transformで1を引いている\n",
    "    video_path_prefix='/mnt/HDD10TB/dataset/UFC101/video',\n",
    "    # clip_sampler=UniformClipSampler(clip_duration=16/25),  # 25FPSを想定して16枚\n",
    "    clip_sampler=RandomClipSampler(clip_duration=16/25),  # 25FPSを想定して16枚\n",
    "    video_sampler=RandomSampler,\n",
    "    decode_audio=False,\n",
    "    transform=train_transform,\n",
    "    )\n",
    "val_set = Ucf101(\n",
    "    data_path='/mnt/HDD10TB/dataset/UFC101/ucfTrainTestlist/testlist01.txt',\n",
    "    video_path_prefix='/mnt/HDD10TB/dataset/UFC101/video',\n",
    "    clip_sampler=RandomClipSampler(clip_duration=16/25),  # 25FPSを想定して16枚\n",
    "    video_sampler=RandomSampler,\n",
    "    decode_audio=False,\n",
    "    transform=val_transform,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9537"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "train_set.num_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3783"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "val_set.num_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/facebookresearch/pytorchvideo/blob/ef2d3a96bb939b12aa0f21fb467d2175b0f05e9f/tutorials/video_classification_example/train.py#L343\n",
    "class LimitDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    To ensure a constant number of samples are retrieved from the dataset we use this\n",
    "    LimitDataset wrapper. This is necessary because several of the underlying videos\n",
    "    may be corrupted while fetching or decoding, however, we always want the same\n",
    "    number of steps per epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.dataset_iter = itertools.chain.from_iterable(\n",
    "            itertools.repeat(iter(dataset), 2)\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return next(self.dataset_iter)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.num_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(LimitDataset(train_set),\n",
    "                            batch_size=args.batch_size,\n",
    "                            drop_last=True,\n",
    "                            num_workers=args.num_workers)\n",
    "val_loader = DataLoader(LimitDataset(val_set),\n",
    "                            batch_size=args.batch_size,\n",
    "                            drop_last=True,\n",
    "                            num_workers=args.num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f6ae82d4a30>,\n",
       " <pytorchvideo.data.labeled_video_dataset.LabeledVideoDataset at 0x7f6b3877b610>)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "train_loader, train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1192, 9537, 1192.125)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "len(train_loader), train_set.num_videos, train_set.num_videos / args.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dict_keys(['video', 'video_name', 'video_index', 'clip_index', 'aug_index', 'label'])\ntorch.Size([3, 16, 224, 224])\ntensor([[-2., -2., -2., -2., -2.],\n        [-2., -2., -2., -2., -2.],\n        [-2., -2., -2., -2., -2.],\n        [-2., -2., -2., -2., -2.],\n        [-2., -2., -2., -2., -2.]])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_set))\n",
    "print(batch.keys())\n",
    "print(batch['video'].shape)\n",
    "print(batch['video'][0, 0, :5, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[91 73  1 50 35 61 93 20]\n",
      "[52 95 12 19 17 83 41 71]\n",
      "[10 44  7 72 31 33 87  0]\n",
      "[78 90 87 73 77 96 33 89]\n",
      "[57 28 51 72 23 15 65 94]\n",
      "[30 32 83  9 74 87 34 79]\n",
      "[85 38 55 86 56 84  2 92]\n",
      "[ 3 52 56 39 31 80 58 32]\n",
      "[69  8 76 15 32 61  3 52]\n",
      "[39 68 94 96 94 88  0 58]\n",
      "[82 68 95 51 22 97 67 74]\n",
      "[51  6  3 20 87 16 51 59]\n",
      "[68 77 48 72 14 95 98 81]\n",
      "[ 3 32 50 98 16  9 87 34]\n",
      "[11 43 40 97 98 40 15 48]\n",
      "[18 31 45 88 97 69 29 83]\n",
      "[ 0 39 77 36 77 96 26 31]\n",
      "[ 55  94  94  30 100  80  28  14]\n",
      "[69 18 63 83  6 82 45 98]\n",
      "[16 69 83 42 93 23 90 37]\n",
      "[ 2 70 41 17 47  2  2 60]\n",
      "[ 28 100  58   6  43  82  61  89]\n",
      "[85 64 88 58 67 22  8 10]\n",
      "[41 60 68 16 86 31 55  6]\n",
      "[62 48 82 17 66 94 85 77]\n",
      "[41  2 90 38 50 49  0 53]\n",
      "[34 41 96 64 12 36 11 40]\n",
      "[83 73 93  7 98 46 37 93]\n",
      "[72 98 12 52  6 63 87 22]\n",
      "[48 60 77 99 25 48 26 43]\n",
      "[48 30 50  3 81 85 55 63]\n",
      "[90 77 59 89 46 49  5 34]\n",
      "[87 98 33 60 24 88 88 43]\n",
      "[86 13 30 77 15 39 42 17]\n",
      "[98  9  5 40 19 68 93 77]\n",
      "[11 30 20 86 36  4 91 22]\n",
      "[79 92 26 48 73 19 93 34]\n",
      "[23 14 59  4 27 83 28 30]\n",
      "[84 33 20 30 58 26 78 25]\n",
      "[20 84 29  8 64 65 12 80]\n",
      "[ 2 53 38 97 80 59 10 72]\n",
      "[20 45 24 31 86  7 90 23]\n",
      "[11 17 34 96 60  7 34 43]\n",
      "[ 8 55 83 52 20 22 38 33]\n",
      "[19 23 12 26 45 25 14 12]\n",
      "[ 81  63 100  56  78  33  48  41]\n",
      "[51  3 14 97 70 94 42 78]\n",
      "[28  9  0 10 60 72  0 22]\n",
      "[22 77 87 76 98 30 94 49]\n",
      "[38  2 67 66 71 59 15 96]\n",
      "[24 44 50 41 91 23  0 61]\n",
      "[33 80 12 76 40 76 18 90]\n",
      "[34 59 90 61 62 24 48 22]\n",
      "[38 64 68 95 41 99 34 26]\n",
      "[23 71 12 42 79 64 59  6]\n",
      "[60 33  9 19 72 82 42 68]\n",
      "[83 62 17  7 15  9 10 38]\n",
      "[ 30  19  80  24  19  38  56 100]\n",
      "[28 55 16 19  1 97 37 10]\n",
      "[ 75   9   4 100   8  43   4  75]\n",
      "[15 30 83 51 59 91 85 27]\n",
      "[12 71 82 52 58 25  3 86]\n",
      "[39 91  5  9 82 16 11 30]\n",
      "[10  2 15 59 43  9 62 53]\n",
      "[36 90 22 81 31 88 66 26]\n",
      "[16 86 78 11 55 63 74 39]\n",
      "[36 21 10 38 37 41 45 17]\n",
      "[65 58 69 96 77 61 80 38]\n",
      "[51 42 22 24 50 73  5 44]\n",
      "[71 19  8 73 83 79 57 38]\n",
      "[85  5 28  6 80 97 21 96]\n",
      "[52  5  1 97  1 44 11 98]\n",
      "[24 49 16 97 26 59 68 68]\n",
      "[30 50 74 51 87 45  6 56]\n",
      "[19 33 29 67 11 53 76 97]\n",
      "[ 59  88  25  43 100  39  74  28]\n",
      "[ 5 89 77 59 62 70 43 95]\n",
      "[37 29 94 30 91 40  7  2]\n",
      "[ 0 25 24 55 98 44 57 86]\n",
      "[72 58 67 69 70 44 82 44]\n",
      "[35 11 30 50 25 25 57 89]\n",
      "[52 91 58 40 53 52 19 92]\n",
      "[ 9 72 79 85 36 23 94 34]\n",
      "[ 1 81 73 15 13 53 38 40]\n",
      "[100  88  51  92  54  62  69  49]\n",
      "[66 12 49 96 26 31 75 47]\n",
      "[ 5 22 61 31 75 34 87 86]\n",
      "[70 87 31 85  4 27 99 90]\n",
      "[62 70 82 27 68 26 73 31]\n",
      "[25 87 56 10 80 43  4 34]\n",
      "[40 82 19 87  3 27 98 11]\n",
      "[29 96 12 68  8 51 74 48]\n",
      "[85 10 76 91 84 78 11 47]\n",
      "[91 64 35 69 82 82 87 97]\n",
      "[15 38 44 91 63 65 43 11]\n",
      "[ 6 87 82 45 70 41 22 67]\n",
      "[31 17 30 33 95 53 65 19]\n",
      "[30 62 39 11 22 32 99 58]\n",
      "[73 12 48 11 15 44 28 40]\n",
      "[37 30 61 68 68 61 10 21]\n",
      "[100  26  91   2  22  43  80  26]\n",
      "[ 2 65 55 64 11  3 44 91]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    print(batch['label'].cpu().numpy())\n",
    "    if i > 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transformの定義．\n",
    "- UCF101を読み込むとuint8なので，255で割ってfloatにする．\n",
    "- torchvisionのUCF101データセットは(T, H, W, C)の形式．しかしpytorchvideoのx3dの入力形式は(B, C, T, H, W)らしいので，それに合わせる．\n",
    "- X3D-Mを想定して，画像を224x224にリサイズする．transform.Resize()はまだ試していないが，この形式ができるかどうか不明（torchvisionのtransformは画像しか扱わないのでムリだと思う）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットはimage, audio, labelの三組を返すが，UCF101には音声がない動画もあり，そのまま使うとdataloaderがバッチにできないというエラーが出てしまう（audioの次元数がサンプルによって異なるため）．そこでcollateでaudioを取り除く．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "メタデータの準備．UCF101の全動画をスキャンして，FPSなどの情報を取得するらしい．かなり時間がかかる．\n",
    "それを保存して再利用（毎回計算し直すと時間の無駄）．\n",
    "コードを見たところ，foldやtrainには無関係で，fpcとsbcにだけ依存するらしいので，それをファイル名にして保存する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UCF101には3つのスプリットがあるので，foldでそれを指定（多分）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データローダーの作成．collateをここで指定．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorchvideoのx3dモデルを作成．\n",
    "webマニュアルにはないが，コードをみると，クリップ長とサイズが指定できる．\n",
    "X3Dは数種類あるが，ここではX3D-Mに合わせた数字を指定（コードのコメントに書いてある）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using cache found in /home/tamaki/.cache/torch/hub/facebookresearch_pytorchvideo_master\n"
     ]
    }
   ],
   "source": [
    "# # X3D-M\n",
    "# # https://github.com/facebookresearch/pytorchvideo/blob/master/pytorchvideo/models/x3d.py#L601\n",
    "# model = x3d.create_x3d(\n",
    "#     input_clip_length=16,\n",
    "#     input_crop_size=224,\n",
    "#     depth_factor=2.2,\n",
    "#     model_num_class=101\n",
    "# ).to(device)\n",
    "\n",
    "num_classes = 101\n",
    "\n",
    "model = torch.hub.load('facebookresearch/pytorchvideo', 'x3d_m', pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.blocks[5].proj = nn.Linear(model.blocks[5].proj.in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ランダムなデータを流し込んで出力されるかを確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(2, 3, 16, 224, 224).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0102, 0.0096, 0.0089, 0.0099, 0.0111, 0.0104, 0.0098, 0.0106, 0.0101,\n",
       "         0.0103, 0.0099, 0.0091, 0.0106, 0.0081, 0.0100, 0.0108, 0.0094, 0.0089,\n",
       "         0.0109, 0.0097, 0.0096, 0.0108, 0.0096, 0.0099, 0.0095, 0.0100, 0.0096,\n",
       "         0.0099, 0.0108, 0.0101, 0.0099, 0.0098, 0.0088, 0.0096, 0.0104, 0.0101,\n",
       "         0.0101, 0.0092, 0.0091, 0.0106, 0.0107, 0.0099, 0.0106, 0.0111, 0.0093,\n",
       "         0.0095, 0.0103, 0.0092, 0.0093, 0.0096, 0.0098, 0.0108, 0.0101, 0.0109,\n",
       "         0.0109, 0.0100, 0.0099, 0.0106, 0.0109, 0.0101, 0.0097, 0.0090, 0.0094,\n",
       "         0.0103, 0.0096, 0.0104, 0.0099, 0.0101, 0.0104, 0.0102, 0.0107, 0.0087,\n",
       "         0.0101, 0.0103, 0.0088, 0.0110, 0.0096, 0.0095, 0.0109, 0.0085, 0.0091,\n",
       "         0.0091, 0.0103, 0.0102, 0.0097, 0.0088, 0.0097, 0.0107, 0.0094, 0.0090,\n",
       "         0.0096, 0.0101, 0.0103, 0.0103, 0.0095, 0.0102, 0.0096, 0.0103, 0.0090,\n",
       "         0.0096, 0.0092],\n",
       "        [0.0099, 0.0105, 0.0091, 0.0109, 0.0106, 0.0097, 0.0098, 0.0098, 0.0103,\n",
       "         0.0092, 0.0097, 0.0101, 0.0110, 0.0084, 0.0096, 0.0092, 0.0096, 0.0108,\n",
       "         0.0097, 0.0093, 0.0092, 0.0096, 0.0108, 0.0094, 0.0094, 0.0100, 0.0086,\n",
       "         0.0096, 0.0104, 0.0099, 0.0095, 0.0107, 0.0097, 0.0113, 0.0096, 0.0092,\n",
       "         0.0101, 0.0097, 0.0105, 0.0107, 0.0108, 0.0102, 0.0102, 0.0096, 0.0102,\n",
       "         0.0101, 0.0096, 0.0101, 0.0100, 0.0094, 0.0097, 0.0103, 0.0094, 0.0100,\n",
       "         0.0098, 0.0105, 0.0105, 0.0106, 0.0098, 0.0088, 0.0107, 0.0084, 0.0097,\n",
       "         0.0099, 0.0096, 0.0095, 0.0094, 0.0097, 0.0104, 0.0095, 0.0100, 0.0099,\n",
       "         0.0104, 0.0102, 0.0098, 0.0102, 0.0111, 0.0093, 0.0098, 0.0091, 0.0093,\n",
       "         0.0104, 0.0105, 0.0102, 0.0098, 0.0097, 0.0099, 0.0097, 0.0103, 0.0104,\n",
       "         0.0099, 0.0102, 0.0102, 0.0092, 0.0093, 0.0090, 0.0103, 0.0110, 0.0103,\n",
       "         0.0095, 0.0098]], device='cuda:0', grad_fn=<ViewBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summaryで中身を確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape               Output Shape\n",
       "==============================================================================================================\n",
       "Net                                                          --                        --\n",
       "├─ModuleList (blocks)                                        --                        --\n",
       "│    └─ResNetBasicStem (0)                                   [4, 3, 16, 224, 224]      [4, 24, 16, 112, 112]\n",
       "│    │    └─Conv2plus1d (conv)                               [4, 3, 16, 224, 224]      [4, 24, 16, 112, 112]\n",
       "│    │    │    └─Conv3d (conv_t)                             [4, 3, 16, 224, 224]      [4, 24, 16, 112, 112]\n",
       "│    │    │    └─Conv3d (conv_xy)                            [4, 24, 16, 112, 112]     [4, 24, 16, 112, 112]\n",
       "│    │    └─BatchNorm3d (norm)                               [4, 24, 16, 112, 112]     [4, 24, 16, 112, 112]\n",
       "│    │    └─ReLU (activation)                                [4, 24, 16, 112, 112]     [4, 24, 16, 112, 112]\n",
       "│    └─ResStage (1)                                          [4, 24, 16, 112, 112]     [4, 24, 16, 56, 56]\n",
       "│    │    └─ModuleList (res_blocks)                          --                        --\n",
       "│    │    │    └─ResBlock (0)                                [4, 24, 16, 112, 112]     [4, 24, 16, 56, 56]\n",
       "│    │    │    └─ResBlock (1)                                [4, 24, 16, 56, 56]       [4, 24, 16, 56, 56]\n",
       "│    │    │    └─ResBlock (2)                                [4, 24, 16, 56, 56]       [4, 24, 16, 56, 56]\n",
       "│    └─ResStage (2)                                          [4, 24, 16, 56, 56]       [4, 48, 16, 28, 28]\n",
       "│    │    └─ModuleList (res_blocks)                          --                        --\n",
       "│    │    │    └─ResBlock (0)                                [4, 24, 16, 56, 56]       [4, 48, 16, 28, 28]\n",
       "│    │    │    └─ResBlock (1)                                [4, 48, 16, 28, 28]       [4, 48, 16, 28, 28]\n",
       "│    │    │    └─ResBlock (2)                                [4, 48, 16, 28, 28]       [4, 48, 16, 28, 28]\n",
       "│    │    │    └─ResBlock (3)                                [4, 48, 16, 28, 28]       [4, 48, 16, 28, 28]\n",
       "│    │    │    └─ResBlock (4)                                [4, 48, 16, 28, 28]       [4, 48, 16, 28, 28]\n",
       "│    └─ResStage (3)                                          [4, 48, 16, 28, 28]       [4, 96, 16, 14, 14]\n",
       "│    │    └─ModuleList (res_blocks)                          --                        --\n",
       "│    │    │    └─ResBlock (0)                                [4, 48, 16, 28, 28]       [4, 96, 16, 14, 14]\n",
       "│    │    │    └─ResBlock (1)                                [4, 96, 16, 14, 14]       [4, 96, 16, 14, 14]\n",
       "│    │    │    └─ResBlock (2)                                [4, 96, 16, 14, 14]       [4, 96, 16, 14, 14]\n",
       "│    │    │    └─ResBlock (3)                                [4, 96, 16, 14, 14]       [4, 96, 16, 14, 14]\n",
       "│    │    │    └─ResBlock (4)                                [4, 96, 16, 14, 14]       [4, 96, 16, 14, 14]\n",
       "│    │    │    └─ResBlock (5)                                [4, 96, 16, 14, 14]       [4, 96, 16, 14, 14]\n",
       "│    │    │    └─ResBlock (6)                                [4, 96, 16, 14, 14]       [4, 96, 16, 14, 14]\n",
       "│    │    │    └─ResBlock (7)                                [4, 96, 16, 14, 14]       [4, 96, 16, 14, 14]\n",
       "│    │    │    └─ResBlock (8)                                [4, 96, 16, 14, 14]       [4, 96, 16, 14, 14]\n",
       "│    │    │    └─ResBlock (9)                                [4, 96, 16, 14, 14]       [4, 96, 16, 14, 14]\n",
       "│    │    │    └─ResBlock (10)                               [4, 96, 16, 14, 14]       [4, 96, 16, 14, 14]\n",
       "│    └─ResStage (4)                                          [4, 96, 16, 14, 14]       [4, 192, 16, 7, 7]\n",
       "│    │    └─ModuleList (res_blocks)                          --                        --\n",
       "│    │    │    └─ResBlock (0)                                [4, 96, 16, 14, 14]       [4, 192, 16, 7, 7]\n",
       "│    │    │    └─ResBlock (1)                                [4, 192, 16, 7, 7]        [4, 192, 16, 7, 7]\n",
       "│    │    │    └─ResBlock (2)                                [4, 192, 16, 7, 7]        [4, 192, 16, 7, 7]\n",
       "│    │    │    └─ResBlock (3)                                [4, 192, 16, 7, 7]        [4, 192, 16, 7, 7]\n",
       "│    │    │    └─ResBlock (4)                                [4, 192, 16, 7, 7]        [4, 192, 16, 7, 7]\n",
       "│    │    │    └─ResBlock (5)                                [4, 192, 16, 7, 7]        [4, 192, 16, 7, 7]\n",
       "│    │    │    └─ResBlock (6)                                [4, 192, 16, 7, 7]        [4, 192, 16, 7, 7]\n",
       "│    └─ResNetBasicHead (5)                                   [4, 192, 16, 7, 7]        [4, 101]\n",
       "│    │    └─ProjectedPool (pool)                             [4, 192, 16, 7, 7]        [4, 2048, 1, 1, 1]\n",
       "│    │    │    └─Conv3d (pre_conv)                           [4, 192, 16, 7, 7]        [4, 432, 16, 7, 7]\n",
       "│    │    │    └─BatchNorm3d (pre_norm)                      [4, 432, 16, 7, 7]        [4, 432, 16, 7, 7]\n",
       "│    │    │    └─ReLU (pre_act)                              [4, 432, 16, 7, 7]        [4, 432, 16, 7, 7]\n",
       "│    │    │    └─AvgPool3d (pool)                            [4, 432, 16, 7, 7]        [4, 432, 1, 1, 1]\n",
       "│    │    │    └─Conv3d (post_conv)                          [4, 432, 1, 1, 1]         [4, 2048, 1, 1, 1]\n",
       "│    │    │    └─ReLU (post_act)                             [4, 2048, 1, 1, 1]        [4, 2048, 1, 1, 1]\n",
       "│    │    └─Dropout (dropout)                                [4, 2048, 1, 1, 1]        [4, 2048, 1, 1, 1]\n",
       "│    │    └─Linear (proj)                                    [4, 1, 1, 1, 2048]        [4, 1, 1, 1, 101]\n",
       "│    │    └─Softmax (activation)                             [4, 101, 1, 1, 1]         [4, 101, 1, 1, 1]\n",
       "│    │    └─AdaptiveAvgPool3d (output_pool)                  [4, 101, 1, 1, 1]         [4, 101, 1, 1, 1]\n",
       "==============================================================================================================\n",
       "Total params: 3,181,623\n",
       "Trainable params: 206,949\n",
       "Non-trainable params: 2,974,674\n",
       "Total mult-adds (G): 18.93\n",
       "==============================================================================================================\n",
       "Input size (MB): 38.54\n",
       "Forward/backward pass size (MB): 5433.65\n",
       "Params size (MB): 12.73\n",
       "Estimated Total Size (MB): 5484.91\n",
       "=============================================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "torchinfo.summary(\n",
    "    model,\n",
    "    (4, 3, 16, 224, 224),\n",
    "    depth=4,\n",
    "    col_names=[\"input_size\",\n",
    "               \"output_size\"],\n",
    "    row_settings=(\"var_names\",)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "便利関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
    "    https://github.com/machine-perception-robotics-group/attention_branch_network/blob/ced1d97303792ac6d56442571d71bb0572b3efd8/utils/misc.py#L59\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        if type(val) == torch.Tensor:\n",
    "            val = val.item()\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def top1(outputs, targets):\n",
    "    batch_size = outputs.size(0)\n",
    "    _, predicted = outputs.max(1)\n",
    "    return predicted.eq(targets).sum().item() / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy.random import randn\n",
    "\n",
    "# train_loss = AverageMeter()\n",
    "# for i in list(range(100)):\n",
    "#     train_loss.update(randn())\n",
    "#     print(train_loss.avg, \n",
    "#           train_loss.count, \n",
    "#           train_loss.sum,\n",
    "#           train_loss.val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvisionのvideo.pyで，ワーニングが多数出るのでそれを抑制．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning,\n",
    "#                                    module='torchvision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eed3c96418e949a296b401c5ad1933ad"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1192.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "932e3f270fe14e7cb5b051d7762694cd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[18 18 18 18 18 64 64 64]\n",
      "[18 18 18 18 18 36 36 36]\n",
      "[18 18 18 18 18 28 28 28]\n",
      "[18 18 18 18 18 36 36 36]\n",
      "[18 18 18 18 18  6  6  6]\n",
      "[18 18 18 18 18  3  3  3]\n",
      "[18 18 18 18 18 67 67 67]\n",
      "[18 18 18 18 18  6  6  6]\n",
      "[18 18 18 18 18 73 73 73]\n",
      "[18 18 18 18 18 95 95 95]\n",
      "[18 18 18 18 18 36 36 36]\n",
      "[18 18 18 18 18  1  1  1]\n",
      "[18 18 18 18 18 81 81 81]\n",
      "[18 18 18 18 18 30 30 30]\n",
      "[18 18 18 18 18 41 41 41]\n",
      "[18 18 18 18 18 42 42 42]\n",
      "[18 18 18 18 18 62 62 62]\n",
      "[18 18 18 18 18 89 89 89]\n",
      "[18 18 18 18 18 10 10 10]\n",
      "[18 18 18 18 18 79 79 79]\n",
      "[18 18 18 18 18 21 21 21]\n",
      "[18 18 18 18 18  9  9  9]\n",
      "[18 18 18 18 18 29 29 29]\n",
      "[18 18 18 18 18 69 69 69]\n",
      "[64 64 64 64 64 64 64 64]\n",
      "[36 36  0  0  0  0  0  0]\n",
      "[28 28 28 28 28 28 28 28]\n",
      "[36 36 76 76 76 76 76 76]\n",
      "[ 6  6  6 42 42 42 42 42]\n",
      "[ 3  3  3  3 93 93 93 93]\n",
      "[67 67 67 67 67 67 67 95]\n",
      "[98 98 98 98 34 34 34 34]\n",
      "[73 73 73 73 73 73 73 73]\n",
      "[95 95 95 95  9  9  9  9]\n",
      "[36 36  5  5  5  5  5  5]\n",
      "[ 1  1  1  1  1  1 70 70]\n",
      "[81 81 81 81 81 81 81  5]\n",
      "[30 30 29 29 29 29 29 29]\n",
      "[41 41 41 41 41 41 23 23]\n",
      "[42 42 15 15 15 15 15 15]\n",
      "[62 62 62 62 62 62 62 62]\n",
      "[89 89 89 89 89 89 89 89]\n",
      "[10 10 10 10 10 10 10 10]\n",
      "[79 79 79 79 79 85 85 85]\n",
      "[21 97 97 97 97 97 97 97]\n",
      "[9 1 1 1 1 1 1 1]\n",
      "[29 29 29 29 29 29 29 29]\n",
      "[69 69 95 95 95 95 95 95]\n",
      "[64 64 64 64 64 64 64 64]\n",
      "[ 0  0  0  0  0 76 76 76]\n",
      "[77 77 77 77 77 77 61 61]\n",
      "[76 76 76 76 18 18 18 18]\n",
      "[100 100 100 100 100 100 100 100]\n",
      "[93 93 93 93 93 55 55 55]\n",
      "[95 95 95 95 95 95 19 19]\n",
      "[93 93 93 93 93 93 93 93]\n",
      "[73 73 73 73 73 73 73 73]\n",
      "[9 9 7 7 7 7 7 7]\n",
      "[ 5  5  5  5  5 71 71 71]\n",
      "[70 70 70 70 70 70 70 70]\n",
      "[5 5 5 5 5 5 5 5]\n",
      "[29 29 29 38 38 38 38 74]\n",
      "[23 23 23 23 90 90 90 90]\n",
      "[15 15 41 41 41 41 41 41]\n",
      "[62 62 62 62 60 60 60 60]\n",
      "[89 89 38 38 38 38 38 38]\n",
      "[10 13 13 48 48 48 48 48]\n",
      "[85 85 85 85 85 85 85 85]\n",
      "[97 97 97 26 26 26 26 26]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "[29 29 26 26 26 26 26 26]\n",
      "[95 95 95 95 95 95 95 95]\n",
      "[64 64 64 33 33 33 33 33]\n",
      "[76 76 76 76 76 76 76 76]\n",
      "[61 61 61 61 61 61 61 61]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[100 100 100 100  26  26  26  26]\n",
      "[55 55 55 55 55 55 55 15]\n",
      "[19 19 19 19 19 19 19 19]\n",
      "[93 93 92 92 92 92 92 92]\n",
      "[73 73 73 73 73 73 73 73]\n",
      "[48 48 48 48 48 48 48 48]\n",
      "[71 71 52 52 52 52 52 52]\n",
      "[70 70 70 70 70 70 70 70]\n",
      "[ 5  5  5  5  5 98 98 98]\n",
      "[74 74 74 74 74 74 74 74]\n",
      "[90 90 90 90 90 90 46 46]\n",
      "[41 41 41 41 41 41 44 44]\n",
      "[60 60 60 60 60 60 60 60]\n",
      "[38 38 64 64 64 64 64 64]\n",
      "[48 48 48 48 48 28 28 28]\n",
      "[85 85 85 85 85 97 97 97]\n",
      "[26 26 26 26 26 26 26 26]\n",
      "[ 1 99 99 99 99 99 99 99]\n",
      "[26 26 26 26 26 26 26 26]\n",
      "[95 87 87 87 87 87 87 87]\n",
      "[33 33 33 33 33 33 33 33]\n",
      "[76 11 11 11 11 11 11 11]\n",
      "[61 61 61 61 61 61 61 61]\n",
      "[18 18 18 18 18 18 18 18]\n",
      "[26 26 26 26 26 26 26 26]\n",
      "[15 15 15 15 15 15 15 15]\n",
      "[ 19  19  19  19  19  19  19 100]\n",
      "[61 61 61 61 61 61 61 61]\n",
      "[10 10 10 10 10 10 10 10]\n",
      "[48 48 48 48 48 48 48 48]\n",
      "[52 52 78 78 78 78 78 46]\n",
      "[44 44 44 44 44 44 44 42]\n",
      "[98 98 98 98 33 33 33 33]\n",
      "[90 90 90 90 90 90 90 90]\n",
      "[46 46 18 18 18 18 18 18]\n",
      "[44 44 44 44 44 44 44 44]\n",
      "[60 60 60 60 60 83 83 83]\n",
      "[64 64 64 64 64 64 64 64]\n",
      "[28 28 28 28 28 50 50 50]\n",
      "[97 97 97 97 97 97 97 97]\n",
      "[26 26 26 26 26 24 24 24]\n",
      "[99 99 99 25 25 25 25 25]\n",
      "[26 26 26 26 67 67 67 67]\n",
      "[87 87 87 87 87 87 87 87]\n",
      "[33 33 33 33 33 57 57 57]\n",
      "[11 11 11 11 11 11 11  6]\n",
      "[61 61 61 61 61 61 61 22]\n",
      "[33 33 33 33 33 33 33 33]\n",
      "[26 26 26 26 26 26 27 27]\n",
      "[91 91 91 91 91 91 32 32]\n",
      "[100 100 100 100 100 100 100 100]\n",
      "[61 61 61 61 61 61 61 61]\n",
      "[10 10 27 27 27 27 27 27]\n",
      "[48 48 48 48 48 48 91 91]\n",
      "[46 46 46 46 96 96 96 96]\n",
      "[42 42 42 42 75 75 75 75]\n",
      "[33 33 33 33 33 33 33 33]\n",
      "[90 90 21 21 21 21 21 67]\n",
      "[100 100 100 100 100 100 100 100]\n",
      "[74 74 74 74 74 74 74 74]\n",
      "[83 83 83 83 83 83 83 83]\n",
      "[64 64 64 64 64 64 64 64]\n",
      "[50 50 50 50 22 22 22 22]\n",
      "[97 22 22 22 22 22 22 22]\n",
      "[24 24 24 24 24 24 24 24]\n",
      "[44 44 44 44 44 44 44 44]\n",
      "[67 67 67 67 67 67 67 67]\n",
      "[97 97 97 97 97 97 97 97]\n",
      "[57 57 57  8  8  8  8  8]\n",
      "[ 6  6 64 64 64 64 64 64]\n",
      "[22 22 22 22 22 22 39 39]\n",
      "[94 94 94 94 94 94 94 94]\n",
      "[ 27  27  27  27  27  27  27 100]\n",
      "[32 32 32 32 32 32 32 32]\n",
      "[100 100 100  14  14  14  23  23]\n",
      "[61 61 74 74 74 74 74 74]\n",
      "[27 77 77 77 77 77 77 77]\n",
      "[91 91 91 99 99 99 99 99]\n",
      "[96 19 19 19 19 19 19 19]\n",
      "[75 75 75 75 75 75 75 75]\n",
      "[33 33 33 33 33 33 33 33]\n",
      "[67 67 67 67 94 94 94 94]\n",
      "[100 100 100 100  80  80  80  80]\n",
      "[74 74 74 15 15 15 15 15]\n",
      "[83 83 83 83 83 83  2  2]\n",
      "[64 64 64 64 64 87 87 87]\n",
      "[22 51 51 51 51 51 51 51]\n",
      "[36 36 36 36 36 36 57 57]\n",
      "[24 24 24 24 90 90 90 90]\n",
      "[44 44  2  2  2  2  2  2]\n",
      "[9 9 9 9 9 3 3 3]\n",
      "[97 97 97 97 21 21 21 21]\n",
      "[ 8 54 54 54 54 54 54 54]\n",
      "[64 64 64 64 64 64 64 64]\n",
      "[39 39 39 39 39 99 99 99]\n",
      "[94 94 94 94 94 94 94  3]\n",
      "[100 100 100 100 100 100 100 100]\n",
      "[32 32 32 32 32 84 84 84]\n",
      "[ 23  42  42  42  42  42  42 100]\n",
      "[74 74 74 97 97 97 97 97]\n",
      "[77 77 77 77 77 77 77 50]\n",
      "[99 99 99 99 99 99 99 22]\n",
      "[73 73 73 73 73 73 73 73]\n",
      "[75 75 75 75 75 75 75 31]\n",
      "[66 66 66 66 66 66 66 66]\n",
      "[94 94 94 94 94 94 94 94]\n",
      "[80 80 80 80 80 80 80 80]\n",
      "[15 15 36 36 36 36 36 65]\n",
      "[ 2  2 25 25 25 25 25 25]\n",
      "[87 87 87 87 87 87 87 87]\n",
      "[51 51 99 99 99 99 99 99]\n",
      "[57 57 57 57 57 57 33 33]\n",
      "[90 90 90 90 90 90 68 68]\n",
      "[ 2  2 79 79 79 79 79 79]\n",
      "[ 3  3  3  3  3  3 15 15]\n",
      "[69 69 69 69 69 69 69 69]\n",
      "[54 63 63 63 63 63 63 63]\n",
      "[64 64 64 64 64 64 64 64]\n",
      "[99 99 99 99 99 57 57 57]\n",
      "[ 3  3  3  3  3 12 12 12]\n",
      "[100 100   9   9   9   9   9   9]\n",
      "[84 81 81 81 81 81 81 81]\n",
      "[100 100 100 100 100 100 100 100]\n",
      "[97 97 97 97 97 97 97 42]\n",
      "[50 50 50 50 50 50 50 50]\n",
      "[22 22 22 22 84 84 84 84]\n",
      "[73 73 73 73 73 73 73 73]\n",
      "[31 31 31 32 32 32 32 53]\n",
      "[66 66 66 34 34 34 34 34]\n",
      "[94 94 94 94 69 69 69 69]\n",
      "[80 80 80 80 80 80 80 80]\n",
      "[65 65 65 65 65 65 65 65]\n",
      "[25 25 25 92 92 92 92 92]\n",
      "[87 87 87 87 87 87 87 87]\n",
      "\n",
      "\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e522c7f37347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-90c01b1a4c9a>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, val, n)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "with tqdm(range(num_epochs)) as pbar_epoch:\n",
    "    for epoch in pbar_epoch:\n",
    "        pbar_epoch.set_description(\"[Epoch %d]\" % (epoch))\n",
    "\n",
    "\n",
    "        with tqdm(enumerate(train_loader),\n",
    "                  total=len(train_loader),\n",
    "                  leave=True) as pbar_loss:\n",
    "\n",
    "            train_loss = AverageMeter()\n",
    "            train_acc = AverageMeter()\n",
    "            model.train()\n",
    "\n",
    "            for batch_idx, batch in pbar_loss:\n",
    "                pbar_loss.set_description(\"[train]\")\n",
    "\n",
    "                inputs, targets = batch['video'].to(device), batch['label'].to(device)\n",
    "                bs = inputs.size(0)  # current batch size, may vary at the end of the epoch\n",
    "\n",
    "                print(targets.cpu().numpy())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss.update(loss, bs)\n",
    "                train_acc.update(top1(outputs, targets), bs)\n",
    "\n",
    "                pbar_loss.set_postfix_str(\n",
    "                    ' | loss={:6.04f} , top1={:6.04f}'\n",
    "                    ' | loss={:6.04f} , top1={:6.04f}'\n",
    "                    ''.format(\n",
    "                    train_loss.avg, train_acc.avg,\n",
    "                    train_loss.val, train_acc.val,\n",
    "                ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}